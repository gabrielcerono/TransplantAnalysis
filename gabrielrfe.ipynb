{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gabrielrfev5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSnprGtxvmEe4wKUJu4Vgg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiVyHdUBqCdJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy as np\r\n",
        "import sklearn as sk\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from random import randint\r\n",
        "import pandas as pd"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufkSfi27k8yh"
      },
      "source": [
        "class RankingRE():\r\n",
        "  def __init__(self, X, y, loops):\r\n",
        "   #X and Y in pandas dataframe.\r\n",
        "    self.X = X\r\n",
        "    self.y = y\r\n",
        "    self.loops = loops\r\n",
        "\r\n",
        "  def rankingborda(self):\r\n",
        "    a = 0\r\n",
        "    rankings = np.zeros(len(self.X.columns),)\r\n",
        "\r\n",
        "    for x in range(self.loops):\r\n",
        "      seed = randint(0, 10000)\r\n",
        "  #Aca tendria que venir el x in range(100):\r\n",
        "  #Spliteas el test \r\n",
        "      X_train, X_fr, y_train, y_fr = train_test_split(self.X, self.y, test_size=0.30, random_state= seed)\r\n",
        "  #Inicializas un random forest\r\n",
        "      rf = RandomForestRegressor(n_estimators=100, random_state=30)\r\n",
        "  # Lo fiteas, y calculas el r2\r\n",
        "      rf.fit(X_train, y_train)\r\n",
        "      r2original = rf.score(X_fr, y_fr)\r\n",
        "  #Le inicializas esto pa hacer columnas\r\n",
        "      r2fr= []\r\n",
        "      columnsrf= []\r\n",
        "  \r\n",
        "\r\n",
        "      for x in self.X.columns:\r\n",
        "    #Si no le pones el train, perdes columnas y no las regeneras\r\n",
        "        X_train, X_fr, y_train, y_fr = train_test_split(self.X, self.y, test_size=0.30, random_state = seed)\r\n",
        "    #Dropeas, columna por columna. \r\n",
        "        X_train = X_train.drop([x], axis=1)\r\n",
        "        X_fr = X_fr.drop([x], axis=1)\r\n",
        "    #Fiteas y sacas el score\r\n",
        "        rf.fit(X_train, y_train)\r\n",
        "        r2 = rf.score(X_fr, y_fr)\r\n",
        "    #Apendeas cada columnas sacada\r\n",
        "        columnsrf.append(x)\r\n",
        "    #Apendeas la diferencia r2\r\n",
        "        r2fr.append(r2original - r2)\r\n",
        "  #La idea seria hacer en cada loop, el dataset ese que hice, pero la columna con los rangos indexarla a otro dataframe. \r\n",
        "      a += 1 \r\n",
        "      resultado = np.array(list(zip(columnsrf, r2fr)))\r\n",
        "      resultadopd = pd.DataFrame(data=resultado, columns=['Variables', 'r2-punish'])\r\n",
        "      resultadopd['ranking'] = resultadopd['r2-punish'].rank(ascending = False)\r\n",
        "      rankings = np.add(resultadopd['ranking'].to_numpy(), rankings)\r\n",
        "  \r\n",
        "    featuresranks = np.dstack((columnsrf, rankings))\r\n",
        "    borda = pd.DataFrame(data = np.squeeze(featuresranks, axis=0), columns=['Categories', 'Borda-Score'])\r\n",
        "\r\n",
        "    return borda\r\n",
        "\r\n",
        "  def rankingr2(self):\r\n",
        "\r\n",
        "    \r\n",
        "    rankings = np.zeros(len(self.X.columns),)\r\n",
        "\r\n",
        "    for x in range(self.loops):\r\n",
        "      seed = randint(0, 10000)\r\n",
        "  #Aca tendria que venir el x in range(100):\r\n",
        "  #Spliteas el test \r\n",
        "      X_train, X_fr, y_train, y_fr = train_test_split(self.X, self.y, test_size=0.30, random_state= seed)\r\n",
        "  #Inicializas un random forest\r\n",
        "      rf = RandomForestRegressor(n_estimators=100, random_state=30)\r\n",
        "  # Lo fiteas, y calculas el r2\r\n",
        "      rf.fit(X_train, y_train)\r\n",
        "      r2original = rf.score(X_fr, y_fr)\r\n",
        "  #Le inicializas esto pa hacer columnas\r\n",
        "      r2fr= []\r\n",
        "      columnsrf= []\r\n",
        "  \r\n",
        "\r\n",
        "      for x in self.X.columns:\r\n",
        "    #Si no le pones el train, perdes columnas y no las regeneras\r\n",
        "        X_train, X_fr, y_train, y_fr = train_test_split(self.X, self.y, test_size=0.30, random_state = seed)\r\n",
        "    #Dropeas, columna por columna. \r\n",
        "        X_train = X_train.drop([x], axis=1)\r\n",
        "        X_fr = X_fr.drop([x], axis=1)\r\n",
        "    #Fiteas y sacas el score\r\n",
        "        rf.fit(X_train, y_train)\r\n",
        "        r2 = rf.score(X_fr, y_fr)\r\n",
        "    #Apendeas cada columnas sacada\r\n",
        "        columnsrf.append(x)\r\n",
        "    #Apendeas la diferencia r2\r\n",
        "        r2fr.append(r2original - r2)\r\n",
        "  #La idea seria hacer en cada loop, el dataset ese que hice, pero la columna con los rangos indexarla a otro dataframe.  \r\n",
        "      resultado = np.array(r2fr)\r\n",
        "      rankings = np.add(resultado, rankings)\r\n",
        "    \r\n",
        "    rankings = np.true_divide(rankings, self.loops)\r\n",
        "    featuresranks = np.dstack((columnsrf, rankings))\r\n",
        "    borda = pd.DataFrame(data = np.squeeze(featuresranks, axis=0), columns=['Categories', 'r2-punish'])\r\n",
        "    borda['ranking'] = borda['r2-punish'].rank(ascending = False)\r\n",
        "\r\n",
        "    return borda"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}